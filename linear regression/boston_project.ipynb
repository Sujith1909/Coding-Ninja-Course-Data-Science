{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #            GRADIENT DESCENT PROJECT(BOSTON_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of        # CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0   -0.407850 -0.487722 -1.266023 -0.272599 -0.576134  1.239974  0.840122   \n",
       "1   -0.407374 -0.487722  0.247057 -0.272599 -1.016689  0.001946 -0.838337   \n",
       "2    0.125179 -0.487722  1.015999 -0.272599  1.367490 -0.439699  0.687212   \n",
       "3    0.028304 -0.487722  1.015999 -0.272599  1.859875 -0.047918  0.801005   \n",
       "4   -0.412408 -0.487722 -0.969827 -0.272599 -0.913029 -0.384137 -0.834781   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "374 -0.204929 -0.487722  1.231945  3.668398  0.434551  2.161728  1.053485   \n",
       "375  0.231398 -0.487722  1.015999 -0.272599  1.367490  0.215644  0.687212   \n",
       "376 -0.408311 -0.487722  0.247057 -0.272599 -1.016689 -0.206055 -0.809889   \n",
       "377 -0.410620 -0.487722 -1.152214 -0.272599 -0.818007  0.068904 -1.826921   \n",
       "378  0.342909 -0.487722  1.015999  3.668398  0.659147  1.041946  1.028593   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT     Y  \n",
       "0   -0.520264 -0.752922 -1.278354 -0.303094  0.410571 -1.097990  37.9  \n",
       "1    0.336351 -0.523001 -0.060801  0.113032  0.291169 -0.520474  21.4  \n",
       "2   -0.577309  1.661245  1.530926  0.806576 -3.795795  0.891076  12.7  \n",
       "3   -0.712836  1.661245  1.530926  0.806576 -0.066050  0.215438  19.9  \n",
       "4    0.300508 -0.752922 -0.957633  0.020560  0.431074  0.029007  22.5  \n",
       "..        ...       ...       ...       ...       ...       ...   ...  \n",
       "374 -0.833960 -0.523001 -0.031105 -1.736418  0.361122 -1.504494  50.0  \n",
       "375 -0.703186  1.661245  1.530926  0.806576 -2.812183  0.499991  14.3  \n",
       "376  0.140451 -0.523001 -0.060801  0.113032  0.332066 -0.334043  20.8  \n",
       "377  0.674814 -0.637962  0.129256 -0.719220  0.203235 -0.744752  22.6  \n",
       "378 -1.232462  1.661245  1.530926  0.806576  0.387875 -1.358713  50.0  \n",
       "\n",
       "[379 rows x 14 columns]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv('train.csv',delimiter=',',skipinitialspace=True)\n",
    "col_name=data.columns\n",
    "print(data.shape)\n",
    "data.describe\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler=preprocessing.MinMaxScaler()\n",
    "y_train=data['Y'].values\n",
    "#print(y_train)\n",
    "data['new_f']=data['CHAS']**2\n",
    "boston=data.copy()\n",
    "boston['Y']=1\n",
    "\n",
    "x_train=boston.values\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_train[:,14]=1\n",
    "y_train.reshape(-1,1)\n",
    "\n",
    "#print(y_train)\n",
    "x_train\n",
    "\n",
    "data1=pd.read_csv('test.csv',delimiter=',',skipinitialspace=True,names=col_name)\n",
    "data1['Y']=1\n",
    "data1['new_f']=data1['CHAS']**2\n",
    "#data1.shape\n",
    "x_test=data1.values\n",
    "x_test=scaler.transform(x_test)\n",
    "x_test[:,14]=1\n",
    "print(x_test.shape)\n",
    "\n",
    "def cost(x,y,m):\n",
    "    total_cost=0\n",
    "    n=x.shape[0]\n",
    "    for i in range(x.shape[0]):\n",
    "        total_cost+=(1/n)*((y[i]-(m*x[i]).sum())**2)\n",
    "    return total_cost\n",
    "\n",
    "def step_gradient(x,y,learning_rate,m):\n",
    "    m_slope=[0]*15\n",
    "    n=x.shape[0]\n",
    "    new_m=[0]*15\n",
    "    for i in range(n):\n",
    "        for j in range(15):\n",
    "            m_slope[j]+=(-2/n)*((y[i]-(m*x[i]).sum())*x[i][j])\n",
    "            new_m[j]=m[j]-learning_rate*m_slope[j]\n",
    "    return new_m\n",
    "            \n",
    "\n",
    "def gd(x_train,y_train,learning_rate,num_iterations):\n",
    "    m=[0]*15\n",
    "    for i in range(num_iterations):\n",
    "        m=step_gradient(x_train,y_train,learning_rate,m)\n",
    "        print(i,\"Cost :\",cost(x_train,y_train,m))\n",
    "    return m\n",
    "\n",
    "def run():\n",
    "    learning_rate=0.24\n",
    "    num_iterations=1000\n",
    "    y_train.reshape(-1,1)\n",
    "    m=gd(x_train,y_train,learning_rate,num_iterations)\n",
    "    return m\n",
    "    \n",
    "\n",
    "def calculate(x_test,m):\n",
    "    y_test=[0]*127\n",
    "    m1=[m]*127\n",
    "    y_test=((x_test*m1).sum(axis=1))\n",
    "    #print(y_test[i])\n",
    "    return y_test\n",
    "\n",
    "m=run()\n",
    "y=calculate(x_test,m)\n",
    "#print(y.shape)\n",
    "np.savetxt('predictions.csv',y,fmt='%.5f',delimiter=',')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
