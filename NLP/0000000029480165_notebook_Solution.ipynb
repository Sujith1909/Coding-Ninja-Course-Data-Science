{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T17:26:37.014475Z",
     "start_time": "2019-08-06T17:26:22.708586Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T17:26:38.585669Z",
     "start_time": "2019-08-06T17:26:38.449887Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\") #10980 rows 12 cols\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T12:24:24.064191Z",
     "start_time": "2019-08-04T12:24:24.059231Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# print(train['negativereason_gold'].nunique())\n",
    "# print(train['negativereason_gold'].value_counts(),\"\\n\")\n",
    "\n",
    "# print(x_test.negativereason_gold.nunique())\n",
    "# print(x_test.negativereason_gold.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T17:26:40.961890Z",
     "start_time": "2019-08-06T17:26:40.947305Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_cols = ['airline_sentiment_gold','name','tweet_id', 'retweet_count','tweet_created','user_timezone','tweet_coord','tweet_location']\n",
    "train.drop(drop_cols, axis = 1, inplace=True)\n",
    "test.drop(drop_cols, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T17:26:41.612911Z",
     "start_time": "2019-08-06T17:26:41.597341Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = ['i',\n",
    " 'me',\n",
    " 'my',\n",
    " 'myself',\n",
    " 'we',\n",
    " 'our',\n",
    " 'ours',\n",
    " 'ourselves',\n",
    " 'you',\n",
    " 'your',\n",
    " 'yours',\n",
    " 'yourself',\n",
    " 'yourselves',\n",
    " 'he',\n",
    " 'him',\n",
    " 'his',\n",
    " 'himself',\n",
    " 'she',\n",
    " 'her',\n",
    " 'hers',\n",
    " 'herself',\n",
    " 'it',\n",
    " 'its',\n",
    " 'itself',\n",
    " 'they',\n",
    " 'them',\n",
    " 'their',\n",
    " 'theirs',\n",
    " 'themselves',\n",
    " 'what',\n",
    " 'which',\n",
    " 'who',\n",
    " 'whom',\n",
    " 'this',\n",
    " 'that',\n",
    " 'these',\n",
    " 'those',\n",
    " 'am',\n",
    " 'is',\n",
    " 'are',\n",
    " 'was',\n",
    " 'were',\n",
    " 'be',\n",
    " 'been',\n",
    " 'being',\n",
    " 'have',\n",
    " 'has',\n",
    " 'had',\n",
    " 'having',\n",
    " 'do',\n",
    " 'does',\n",
    " 'did',\n",
    " 'doing',\n",
    " 'a',\n",
    " 'an',\n",
    " 'the',\n",
    " 'and',\n",
    " 'but',\n",
    " 'if',\n",
    " 'or',\n",
    " 'because',\n",
    " 'as',\n",
    " 'until',\n",
    " 'while',\n",
    " 'of',\n",
    " 'at',\n",
    " 'by',\n",
    " 'for',\n",
    " 'with',\n",
    " 'about',\n",
    " 'against',\n",
    " 'between',\n",
    " 'into',\n",
    " 'through',\n",
    " 'during',\n",
    " 'before',\n",
    " 'after',\n",
    " 'above',\n",
    " 'below',\n",
    " 'to',\n",
    " 'from',\n",
    " 'up',\n",
    " 'down',\n",
    " 'in',\n",
    " 'out',\n",
    " 'on',\n",
    " 'off',\n",
    " 'over',\n",
    " 'under',\n",
    " 'again',\n",
    " 'further',\n",
    " 'then',\n",
    " 'once',\n",
    " 'here',\n",
    " 'there',\n",
    " 'when',\n",
    " 'where',\n",
    " 'why',\n",
    " 'how',\n",
    " 'all',\n",
    " 'any',\n",
    " 'both',\n",
    " 'each',\n",
    " 'few',\n",
    " 'more',\n",
    " 'most',\n",
    " 'other',\n",
    " 'some',\n",
    " 'such',\n",
    " 'no',\n",
    " 'nor',\n",
    " 'not',\n",
    " 'only',\n",
    " 'own',\n",
    " 'same',\n",
    " 'so',\n",
    " 'than',\n",
    " 'too',\n",
    " 'very',\n",
    " 's',\n",
    " 't',\n",
    " 'can',\n",
    " 'will',\n",
    " 'just',\n",
    " 'don',\n",
    " 'should',\n",
    " 'now']\n",
    "stops += list(punctuation)\n",
    "stops += ['flight','airline','flights','AA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T17:26:47.245154Z",
     "start_time": "2019-08-06T17:26:42.658559Z"
    }
   },
   "outputs": [],
   "source": [
    "abbreviations = {'ppl': 'people','cust':'customer','serv':'service','mins':'minutes','hrs':'hours','svc': 'service',\n",
    "           'u':'you','pls':'please'}\n",
    "\n",
    "train_index = train[~train.negativereason_gold.isna()].index\n",
    "test_index = test[~test.negativereason_gold.isna()].index\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    tweet = row.text\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',tweet) #remove links\n",
    "    tweet = re.sub('@[^\\s]+','',tweet) #remove usernames\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet) #remove additional whitespaces\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) #replace #word with word\n",
    "    tweet = tweet.strip('\\'\"') #trim tweet\n",
    "    words = []\n",
    "    for word in tweet.split():\n",
    "#         if not hasNumbers(word):\n",
    "        if word.lower() not in stops:\n",
    "            if word in list(abbreviations.keys()):\n",
    "                words.append(abbreviations[word])\n",
    "            else:\n",
    "                words.append(word.lower())   \n",
    "    tweet = \" \".join(words)\n",
    "    tweet = \" %s %s\" % (tweet, row.airline)\n",
    "    row.text = tweet\n",
    "    if index in train_index:\n",
    "        row.text = \" %s %s\" % (row.text, row.negativereason_gold)\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    tweet = row.text\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',tweet) #remove links\n",
    "    tweet = re.sub('@[^\\s]+','',tweet) #remove usernames\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet) #remove additional whitespaces\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) #replace #word with word\n",
    "    tweet = tweet.strip('\\'\"') #trim tweet\n",
    "    words = []\n",
    "    for word in tweet.split(): \n",
    "#         if not hasNumbers(word):\n",
    "        if word.lower() not in stops:\n",
    "            if word in list(abbreviations.keys()):\n",
    "                words.append(abbreviations[word])\n",
    "            else:\n",
    "                words.append(word.lower())\n",
    "    tweet = \" \".join(words)\n",
    "    tweet = \" %s %s\" % (tweet, row.airline)\n",
    "    row.text = tweet\n",
    "    if index in test_index:\n",
    "        row.text = \" %s %s\" % (row.text, row.negativereason_gold)\n",
    "\n",
    "del train['negativereason_gold']\n",
    "del test['negativereason_gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T17:26:52.848188Z",
     "start_time": "2019-08-06T17:26:50.534082Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def deEmojify(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    row.text = deEmojify(row.text)\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    row.text = deEmojify(row.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T17:26:55.482112Z",
     "start_time": "2019-08-06T17:26:52.850905Z"
    }
   },
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    words = row.text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if not hasNumbers(word):\n",
    "            new_words.append(word)\n",
    "    row.text = \" \".join(new_words)\n",
    "    \n",
    "for index, row in test.iterrows():\n",
    "    words = row.text.split()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if not hasNumbers(word):\n",
    "            new_words.append(word)\n",
    "    row.text = \" \".join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T17:26:55.560184Z",
     "start_time": "2019-08-06T17:26:55.485923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>scheduled morning, days fact, yes..not sure ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>seeing workers time time going beyond love fly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>flew ord miami back great crew, service legs. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>that's horse radish Southwest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>ord delayed air force one, last sbn minutes la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment    airline  \\\n",
       "0          negative  Southwest   \n",
       "1          positive  Southwest   \n",
       "2          positive     United   \n",
       "3          negative  Southwest   \n",
       "4          negative     United   \n",
       "\n",
       "                                                text  \n",
       "0  scheduled morning, days fact, yes..not sure ev...  \n",
       "1  seeing workers time time going beyond love fly...  \n",
       "2  flew ord miami back great crew, service legs. ...  \n",
       "3                      that's horse radish Southwest  \n",
       "4  ord delayed air force one, last sbn minutes la...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating vocab and data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T17:56:34.904385Z",
     "start_time": "2019-08-06T17:56:34.631243Z"
    }
   },
   "outputs": [],
   "source": [
    "v = TfidfVectorizer(analyzer='word', max_features=3150, max_df = 0.8, ngram_range=(1,1))\n",
    "train_features= v.fit_transform(train.text)\n",
    "test_features=v.transform(test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T17:56:38.481957Z",
     "start_time": "2019-08-06T17:56:38.333543Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C = 2.1, solver='liblinear', multi_class='auto')\n",
    "clf.fit(train_features,train['airline_sentiment'])\n",
    "pred = clf.predict(test_features)\n",
    "with open('predictions_twitter.csv', 'w') as f:\n",
    "    for item in pred:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T15:53:29.055261Z",
     "start_time": "2019-08-06T15:53:19.146191Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel=\"linear\", C= 0.96 , gamma = 'scale')\n",
    "# clf = SVC(C = 1000, gamma = 0.001)\n",
    "clf.fit(train_features, train['airline_sentiment'])\n",
    "pred = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8693078324225865"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(train_features,train['airline_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-06T15:53:29.649946Z",
     "start_time": "2019-08-06T15:53:29.638435Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('predictions_twitter2.csv', 'w') as f: #less accurate\n",
    "    for item in pred:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-04T10:09:48.615243Z",
     "start_time": "2019-08-04T10:09:48.589411Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# v.get_feature_names()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
